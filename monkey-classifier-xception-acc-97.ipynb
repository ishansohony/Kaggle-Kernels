{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import matplotlib.pylab as plt\nimport numpy as np\nimport pandas as pd\nfrom keras import models, layers, optimizers\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29d94bb9ca6a1795237e572ca05ee63163073c41"},"cell_type":"code","source":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n    \n!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/\n\nprint(\"Available Pretrained Models:\")\n!ls ~/.keras/models\n","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"monkey_species = os.listdir('../input/10-monkey-species/training/training')\nprint(\"Number of Categories:\", len(monkey_species))\nprint(\"Categories: \", monkey_species)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7c1a7675f9477c5ef6c0518c7ca67d6ff5ff8476"},"cell_type":"code","source":"# dimensions of our images.\nimg_width, img_height = 224, 224 # we set the img_width and img_height according to the pretrained models we are\n# going to use. The input size for ResNet-50 is 224 by 224 by 3.\n\ntrain_data_dir = '../input/10-monkey-species/training/training'\nvalidation_data_dir = '../input/10-monkey-species/validation/validation'\nbatch_size = 4","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5e74fe6faff05743267c7354331d5b873206ade"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range = 30,\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical')","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b40f0e63008b4c5e5a42678da30f89b379a777ed"},"cell_type":"code","source":"nb_train_samples = len(train_generator.classes)\nnb_validation_samples = len(validation_generator.classes)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75248d96a7588bfd7c52b67740debf4d6ada65fd"},"cell_type":"code","source":"import pandas as pd\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a04562dcea6343c0cb140e8865bbba0ccd20217c"},"cell_type":"code","source":"training_data = pd.DataFrame(train_generator.classes, columns=['classes'])\ntesting_data = pd.DataFrame(validation_generator.classes, columns=['classes'])","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ba8eed8a6c42f300c2a42cf9a694b23ccf000d0d"},"cell_type":"code","source":"def create_stack_bar_data(col, df):\n    aggregated = df[col].value_counts().sort_index()\n    x_values = aggregated.index.tolist()\n    y_values = aggregated.values.tolist()\n    return x_values, y_values","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba9f9e7dca1cc19f8d468faf7dce35fb0c2009fe"},"cell_type":"code","source":"x1, y1 = create_stack_bar_data('classes', training_data)\nx1 = list(train_generator.class_indices.keys())\n\ntrace1 = go.Bar(x=x1, y=y1, opacity=0.75, name=\"Class Count\")\nlayout = dict(height=400, width=1200, title='Class Distribution in Training Data', legend=dict(orientation=\"h\"), \n                yaxis = dict(title = 'Class Count'))\nfig = go.Figure(data=[trace1], layout=layout);\niplot(fig);","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c71abaaa9a844682ce081c23944ac7abd02c9d3"},"cell_type":"code","source":"x1, y1 = create_stack_bar_data('classes', testing_data)\nx1 = list(validation_generator.class_indices.keys())\n\ntrace1 = go.Bar(x=x1, y=y1, opacity=0.75, name=\"Class Count\")\nlayout = dict(height=400, width=1100, title='Class Distribution in Validation Data', legend=dict(orientation=\"h\"), \n                yaxis = dict(title = 'Class Count'))\nfig = go.Figure(data=[trace1], layout=layout);\niplot(fig);","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa685a97dc96990a5b79047610d0ea225a4099e9","collapsed":true},"cell_type":"code","source":"#import inception with pre-trained weights. do not include fully #connected layers\nXception_base = applications.Xception(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = Xception_base.output\nx = layers.GlobalAveragePooling2D()(x)\n# add a fully-connected layer\nx = layers.Dense(512, activation='relu')(x)\n# and a fully connected output/classification layer\npredictions = layers.Dense(int(len(train_generator.class_indices.keys())), activation='softmax')(x)\n# create the full network so we can train on it\nXception_transfer = models.Model(inputs=Xception_base.input, outputs=predictions)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"011a00a86e29a7e9b7e0bb33a167a3ecb973224e"},"cell_type":"code","source":"Xception_transfer.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7be39e9a2a096fc878f93706a9793d6b700cb3a"},"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f9bc704fd044a31ed250e7d2becb9052ef1f52","collapsed":true},"cell_type":"code","source":"import tensorflow as tf\nwith tf.device(\"/device:GPU:0\"):\n    history = Xception_transfer.fit_generator(\n    train_generator,\n    epochs=10, shuffle = True, verbose = 1, validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61037bf1746b409334284cdf46bcbff72a70454a","collapsed":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9dfa9ed173fc3a3a9cf73deaee3af1d3cbda8d96"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}